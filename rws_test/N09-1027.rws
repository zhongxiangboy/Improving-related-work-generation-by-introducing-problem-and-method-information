there have been significant efforts in the both the monolingual parsing and machine translation literature to address the impact of the map approximation and the choice of labels in their respective models ;we survey the work most closely related to our approach. 0 (may and knight 2006);(kumar and byrne 2004) extract nbest lists containing unique translations rather than unique derivations , while use the minimum bayes risk decision rule to select the lowest risk ( highest bleu score ) translation rather than derivation from an n-best list. 0 (tromble et al. 2008) extend this work to lattice structures. all of these approaches only marginalize over alternative candidate derivations generated by a map-driven decoding process. 0 (blunsom et al. 2007) more recently , work by propose a purely discriminative model whose decoding step approximates the selection of the most likely translation via beam search. 1 (matsusaki et al. 2005);(petrov et al. 2006) and propose automatically learning annotations that add information to categories to improve monolingual parsing quality. since the parsing task requires selecting the most non-annotated tree , the annotations add an additional level of structure that must be marginalized during search. they demonstrate improvements in parse quality only when a variational approximation is used to select the most likely unannotated tree rather than simply stripping annotations from the map annotated tree. in our work , we focused on approximating the selection of the most likely unlabeled derivation during search , rather than as a post-processing operation ;the methods described above might improve this approximation , at some computational expense. 
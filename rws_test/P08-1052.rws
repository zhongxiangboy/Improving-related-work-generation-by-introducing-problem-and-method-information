characterizing semantic relations. 0 (turney and littman 2005) characterize the relationship between two words as a vector with coordinates corresponding to the web frequencies of 128 fixed phrases like " x for y " and " y for x " instantiated from a fixed set of 64 joining terms like for , such as , not the , is * , etc. these vectors are used in a nearest-neighbor classifier to solve sat verbal analogy problems , yielding 47 % accuracy. 0 (nastase and szpakowicz 2003);(turney and littman 2005) the same approach is applied to classifying noun-modifier pairs : using the diverse dataset of , achieve f-measures of 26.5 % with 30 fine-grained relations , and 43.2 % with 5 course-grained relations. 0 (turney 2005) extends the above approach by introducing the latent relational analysis ( lra ) , which uses automatically generated synonyms , learns suitable patterns , and performs singular value decomposition in order to smooth the frequencies. 0 (turney, 2006b) the full algorithm consists of 12 steps described in detail in . when applied to sat questions , it achieves the state-of-the-art accuracy of 56 %. on the diverse dataset , it yields an f-measure of 39.8 % with 30 classes , and 58 % with 5 classes. 0 (turney 2006a) presents an unsupervised algorithm for mining the web for patterns expressing implicit semantic relations. for example , cause ( e.g. , cold virus ) is best characterized by " x * causes x " and " y in * early x " is the best pattern for temporal ( e.g. , morning frost ). with 5 classes , he achieves f-measure = 50.2 %. noun-noun compound semantics.  reduces the problem of noun compound interpretation to choosing the best paraphrasing preposition from the following set : of , for , in , at , on , from , with or about. he achieved 40 % accuracy using corpus frequencies. (lapata and keller 2005) this result was improved to 55.7 % by who used web-derived n-gram frequencies. (barker and szpakowicz 1998) use syntactic clues and the identity of the nouns in a nearest-neighbor classifier , achieving 60-70 % accuracy. (rosario and hearst 2001) used a discriminative classifier to assign 18 relations for noun compounds from biomedical text , achieving 60 % accuracy. (rosario et al. 2002) reported 90 % accuracy with a " descent of hierarchy " approach which characterizes the relationship between the nouns in a bioscience noun-noun compound based on the mesh categories the nouns belong to. (girju et al. 2005) apply both classic ( svm and decision trees ) and novel supervised models ( semantic scattering and iterative semantic specialization ) , using wordnet , word sense disambiguation , and a set of linguistic features. they test their system against both lauer 's 8 prepositional paraphrases and another set of 21 semantic relations , achieving up to 54 % accuracy on the latter. (nakov and hearst, 2006) in a previous work , we have shown that the relationship between the nouns in a noun-noun compound can be characterized using verbs extracted from the web , but we provided no formal evaluation. (kim and baldwin 2006) characterized the semantic relationship in a noun-noun compound using the verbs connecting the two nouns by comparing them to predefined seed verbs. their approach is highly resource intensive ( uses wordnet , corelex and moby 's thesaurus ) , and is quite sensitive to the seed set of verbs : on a collection of 453 examples and 19 relations , they achieved 52.6 % accuracy with 84 seed verbs , but only 46.7 % with 57 seed verbs. paraphrase acquisition. our method of extraction of paraphrasing verbs and prepositions is similar to previous paraphrase acquisition approaches. (lin and pantel 2001) extract paraphrases from dependency tree paths whose ends contain semantically similar sets of words by generalizing over these ends. for example , given " x solves y " , they extract paraphrases like " x finds a solution to y " , " x tries to solve y " , x resolves y , y is resolved by x , etc. (shinyama et al. 2002) the approach is extended by , who use named entity recognizers and look for anchors belonging to matching semantic classes , e.g. , location , organization. (nakov et al. 2004) the idea is further extended by , who apply it in the biomedical domain , imposing the additional restriction that the sentences from which the paraphrases are extracted cite the same target paper. word similarity. (alshawi and carter, 1994);(grishman and sterling, 1994);(lin, 1998) another important group of related work is on using syntactic dependency features in a vector-space model for measuring word similarity , e.g. ,  . for example , given a noun , extracts verbs that have that noun as a subject or object , and adjectives that modify it. 
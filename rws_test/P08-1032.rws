automatic image annotation is a popular task in computer vision. (vailaya et al., 2001);(smeulders et al., 2000) the earliest approaches are closely related to image classification  , where pictures are assigned a set of simple descriptions such as indoor , outdoor , landscape , people , animal. a binary classifier is trained for each concept , sometimes in a " one vs all " setting. the focus here is mostly on image processing and good feature selection ( e.g. , colour , texture , contours ) rather than the annotation task itself. recently , much progress has been made on the image annotation task thanks to three factors. the availability of the corel database , the use of unsupervised methods and new insights from the related fields of natural language processing and information retrieval. (mori et al., 1999) the co-occurrence model collects co-occurrence counts between words and image features and uses them to predict annotations for new images. (duygulu et al. 2002) improve on this model by treating image regions and keywords as a bi-text and using the em algorithm to construct an image region-word dictionary. another way of capturing co-occurrence information is to introduce latent variables linking image features with words. standard latent semantic analysis ( lsa ) and its probabilistic variant ( plsa ) have been applied to this task .  propose a hierarchical latent model in order to account for the fact that some words are more general than others. (blei and jordan, 2003) more sophisticated graphical models have also been employed including gaussian mixture models ( gmm ) and latent dirichlet allocation ( lda ). (lavrenko et al., 2003);(feng et al., 2004) finally , relevance models originally developed for information retrieval , have been successfully applied to image annotation . a key idea behind these models is to find the images most similar to the test image and then use their shared keywords for annotation. our approach differs from previous work in two important respects. firstly , our ultimate goal is to develop an image annotation model that can cope with real-world images and noisy data sets. to this end we are faced with the challenge of building an appropriate database for testing and training purposes. our solution is to leverage the vast resource of images available on the web but also the fact that many of these images are implicitly annotated. for example , news articles often contain images whose captions can be thought of as annotations. secondly , we allow our image annotation model access to knowledge sources other than the image and its keywords. this is relatively straightforward in our case ; an image and its accompanying document have shared content , and we can use the latter to glean information about the former. but we hope to illustrate the more general point that auxiliary linguistic information can indeed bring performance improvements on the image annotation task. 
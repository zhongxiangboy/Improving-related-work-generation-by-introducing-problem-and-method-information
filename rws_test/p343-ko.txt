abstract . our system for this years task features entirely new question classification , data storage and access , and answer processing components . question classification based on answer processing components
integrating web-based and corpus-based techniques for question answering . this years main task included definition and list questions in addition to factoid questions .although web-based techniques have proven effective in handling factoid questions , they are less applicable to tackling definition and list questions .the data- driven approach implicitly assumes that each natural language question has a unique answer .since a single answer instance is sufficient , algorithms were designed to trade recall for precision .for list and definition questions , however , a more balanced approach is required , since multiple answers are not only desired , but necessary .we believe that the best strategy is to integrate web-based approaches with more traditional question answering techniques driven by document retrieval and named-entity detection .corpus- and web-based strategies should play complementary roles in an overall question answering framework . list and definition questions based on web - based and corpus - based techniques
comparing statistical and content-based techniques for answer validation on the web . answer validation is an emerging topic in question answering , where open domain systems are often required to rank huge amounts of candidate answers .we present a novel approach to answer validation based on the intuition that the amount of implicit knowledge which connects an answer to a question can be estimated by exploiting the redundancy of web information .two techniques are considered in this paper : a statistical approach , which uses the web to obtain a large amount of pages , and a content-based approach , which analyses text snippets retrieved by the search engine .both the approaches do not require to download the documents .experiments carried out on the trec-2001 judged-answer collection show that a combination of the two approaches achieves a high level ofperformance ( i.e. about 88 % success rate ) .the simplicity and the efficiency of these web-based techniques make them suitable to be used as a module in question answering systems . question answering systems based on statistical and content - based techniques
cogex : a logic prover for question answering . recent trec results have demonstrated the need for deeper text understanding methods .this paper introduces the idea of automated reasoning applied to question answering and shows the feasibility of integrating a logic prover into a question answering system .the approach is to transform questions and answer passages into logic representations .world knowledge axioms as well as linguistic axioms are supplied to the prover which renders a deep understanding of the relationship between question text and answer text .moreover , the trace of the proofs provide answer justifications .the results show that the prover boosts the performance of the qa system on trec questions by 30 % . question answering based on deeper text understanding methods
extending the javelin qa system with domain semantics . this paper presents the current status of work to extend the javelin qa system with domain semantics for question answering in restricted domains .we discuss how the original architecture was extended , and how the system modules must be adjusted to incorporate knowledge from existing ontologies and information provided by third-party annotation tools . question answering based on third - party annotation tools
mining knowledge from wikipedia for the question answering task . although significant advances have been made recently in the question answering technology , more steps have to be undertaken in order to obtain better results .moreover , the best systems at the clef and trec evaluation exercises are very complex systems based on custom-built , expensive ontologies whose aim is to provide the systems with encyclopedic knowledge .in this paper we investigated the use of wikipedia , the open domain encyclopedia , for the question answering task .previous works considered wikipedia as a resource where to look for the answers to the questions .we focused on some different aspects of the problem , such as the validation of the answers as returned by our question answering system and on the use of wikipedia categories in order to determine a set of patterns that should fit with the expected answer .validation consists in , given a possible answer , saying wether it is the right one or not .the possibility to exploit the categories of wikipedia was not considered until now .we performed our experiments using the spanish version of wikipedia , with the set of questions of the last clef spanish monolingual exercise .results show that wikipedia is a potentially useful resource for the question answering task . question answering task based on question answering technology
type checking in open-domain question answering . open domain question answering ( qa ) systems have to bridge the potential vocabulary mismatch between a question and its candidate answers .one can view this as a recall problem and address it accordingly .recall oriented strategies to qa may generate considerable amounts of noise .to combat this , many open domain qa systems contain an explicit filtering or re-ranking component , which often check whether the answer is of the correct semantic type .particular classes of questions expect specific answer types to which all of their answers should belong .we compare two kinds of strategies for answer type checking for open domain qa .one is redundancy-based and builds on the intuition that the amount of implicit knowledge which connects an answer to a question can be estimated by exploiting the redundancy of information available on the web .the other is knowledge-intensive , and exploits structured and semi-structured data sources to determine , with high confidence , the semantic type of suggested answers . open - domain question answering based on recall oriented strategies
answer selection and confidence estimation . we describe bbn ï¿½ s question answering work at trec 2002 .we focus on two issues : answer selection and confidence estimation .we found that some simple constraints on the candidate answers can improve a pure irbased technique for answer selection .we also found that a few simple features derived from the question-answer pairs can be used for effective confidence estimation .our results also confirmed earlier findings that the world-wide web is a very useful resource for answering trec-style factoid questions . confidence estimation based on confidence estimation
qualifier in trec-12 qa main task . this paper describes a question answering system and its various modules to solve definition , factoid and list questions defined in the trec12 main task .in particular , we tackle the factoid qa task by event-based question answering .each qa event comprises of elements describing different facets like time , location , object , action etc .by analyzing the external knowledge from pre-retrieved trec documents , web documents , wordnet and ontology to discover the qa event structure , we explore the inherent associations among qa elements and then obtain the answers .there are three subsystems working parallel to handle definition , factoid , and list questions separately .we highlight the shared modules , fine-grained named entity recognition , anaphora resolution and canonicalization co-reference resolution , among the three subsystems as well . fine - grained named entity recognition based on event - based question answering
in question answering , two heads are better than one . motivated by the success of ensemble methods in machine learning and other areas of natural language processing , we developed a multi- strategy and multi-source approach to question answering which is based on combining the results from different answering agents searching for answers in multiple corpora .the answering agents adopt fundamentally different strategies , one utilizing primarily knowledge-based mechanisms and the other adopting statistical techniques .we present our multi-level answer resolution algorithm that combines results from the answering agents at the question , passage , and / or answer levels .experiments evaluating the effectiveness of our answer resolution algorithm show a 35.0 % relative improvement over our baseline system in the number of questions correctly answered , and a 32.8 % improvement according to the average precision metric . natural language processing based on multi - strategy and multi - source approach
how to select an answer string ? given a question q and a sentence / paragraph sp that is likely to contain the answer to q , an answer selection module is supposed to select the exact answer sub-string a c sp .we study three distinct approaches to solving this problem : one approach uses algorithms that rely on rich knowledge bases and sophisticated syntactic / semantic processing ; one approach uses patterns that are learned in an unsupervised manner from the web , using computational biology-inspired alignment algorithms ; and one approach uses statistical noisy-channel algorithms similar to those used in machine translation .we assess the strengths and weaknesses of these three approaches and show how they can be combined using a maximum entropy-based framework . machine translation based on computational biology - inspired alignment algorithms

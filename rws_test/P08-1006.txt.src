0	evaluating the accuracy of an unlexicalized statistical parser on the parc depbank . we evaluate the accuracy of an unlexicalized statistical parser , trained on 4k treebanked sentences from balanced data and tested on the parc depbank .we demonstrate that a parser which is competitive in accuracy ( without sacrificing processing speed ) can be quickly tuned without reliance on large in-domain manually- constructed treebanks .this makes it more practical to use statistical parsers in applications that need access to aspects of predicate-argument structure .the comparison of systems using depbank is not straightforward , so we extend and validate depbank and highlight a number of representation and scoring issues for relational evaluation schemes .  based on unlexicalized statistical parser
1	formalism-independent parser evaluation with ccg and depbank . a key question facing the parsing community is how to compare parsers which use different grammar formalisms and produce different output .evaluating a parser on the same resource used to create it can lead to non-comparable accuracy scores and an over-optimistic view of parser performance .in this paper we evaluate a ccg parser on depbank , and demonstrate the difficulties in converting the parser output into depbank grammatical relations .in addition we present a method for measuring the effectiveness of the conversion , which provides an upper bound on parsing accuracy .the ccg parser obtains an f-score of 81.9 % on labelled dependencies , against an upper bound of 84.8 % .we compare the ccg parser against the rasp parser , outperforming rasp by over 5 % overall and on the majority of dependency types . parsing community based on formalism - independent parser evaluation
2	benchmarking natural-language parsers for biological applications using dependency graphs . interest is growing in the application of syntactic parsers to natural language processing problems in biology , but assessing their performance is difficult because differences in linguistic convention can falsely appear to be errors .we present a method for evaluating their accuracy using an intermediate representation based on dependency graphs , in which the semantic relationships important in most information extraction tasks are closer to the surface .we also demonstrate how this method can be easily tailored to various application-driven criteria .results : using the genia corpus as a gold standard , we tested four open-source parsers which have been used in bioinformatics projects .we first present overall performance measures , and test the two leading tools , the charniak-lease and bikel parsers , on subtasks tailored to reflect the requirements of a system for extracting gene expression relationships .these two tools clearly outperform the other parsers in the evaluation , and achieve accuracy levels comparable to or exceeding native dependency parsers on similar tasks in previous biological evaluations .conclusion : evaluating using dependency graphs allows parsers to be tested easily on criteria chosen according to the semantics of particular biological applications , drawing attention to important mistakes and soaking up many insignificant differences that would otherwise be reported as errors .generating high-accuracy dependency graphs from the output of phrase-structure parsers also provides access to the more detailed syntax trees that are used in several natural- language processing techniques . extracting gene expression relationships based on natural - language processing techniques
3	speed and accuracy in shallow and deep stochastic parsing . this paper reports some experiments that compare the accuracy and performance of two stochastic parsing systems .the currently popular collins parser is a shallow parser whose output contains more detailed semantically- relevant information than other such parsers .the xle parser is a deep-parsing system that couples a lexical functional grammar to a log- linear disambiguation component and provides much richer representations theory .we measured the accuracy of both systems against a gold standard of the parc 700 dependency bank , and also measured their processing times .we found the deep-parsing system to be more accurate than the collins parser with only a slight reduction in parsing speed .  based on log - linear disambiguation component
4	bioinfer : a corpus for information extraction in the biomedical domain . background : lately , there has been a great interest in the application of information extraction methods to the biomedical domain , in particular , to the extraction of relationships of genes , proteins , and rna from scientific publications .the development and evaluation of such methods requires annotated domain corpora .results : we present bioinfer ( bio information extraction resource ) , a new public resource providing an annotated corpus of biomedical english .we describe an annotation scheme capturing named entities and their relationships along with a dependency analysis of sentence syntax .we further present ontologies defining the types of entities and relationships annotated in the corpus .currently , the corpus contains 1 100 sentences from abstracts of biomedical research articles annotated for relationships , named entities , as well as syntactic dependencies .supporting software is provided with the corpus .the corpus is unique in the domain in combining these annotation types for a single set of sentences , and in the level of detail of the relationship annotation .conclusion : we introduce a corpus targeted at protein , gene , and rna relationships which serves as a resource for the development of information extraction systems and their components such as parsers and domain analyzers .the corpus will be maintained and further developed with a current version being available at http : / / www.it.utu.fi / bioinfer . extraction of relationships of genes based on dependency analysis of sentence syntax
5	on the unification of syntactic annotations under the stanford dependency scheme : a case study on bioinfer and genia . several incompatible syntactic annotation schemes are currently used by parsers and corpora in biomedical information extraction .the recently introduced stanford dependency scheme has been suggested to be a suitable unifying syntax formalism .in this paper , we present a step towards such unification by creating a conversion from the link grammar to the stanford scheme .further , we create a version of the bioinfer corpus with syntactic annotation in this scheme .we present an application-oriented evaluation of the transformation and assess the suitability of the scheme and our conversion to the unification of the syntactic annotations of bioinfer and the genia treebank .we find that a highly reliable conversion is both feasible to create and practical , increasing the applicability of both the parser and the corpus to information extraction . unification of syntactic annotations based on incompatible syntactic annotation schemes
6	the impact of parse quality on syntactically-informed statistical machine translation . we investigate the impact of parse quality on a syntactically-informed statistical machine translation system applied to technical text .we vary parse quality by varying the amount of data used to train the parser .as the amount of data increases , parse quality improves , leading to improvements in machine translation output and results that significantly outperform a state-of-the-art phrasal baseline . syntactically - informed statistical machine translation based on syntactically - informed statistical machine translation system
7	using the penn treebank to evaluate non-treebank parsers . this paper describes a method for conducting evaluations of treebank and non-treebank parsers alike against the english language u. penn treebank ( marcus et al. , 1993 ) using a metric that focuses on the accuracy of relatively non-controversial aspects of parse structure .our conjecture is that if we focus on maximal projections of heads ( mph ) , we are likely to find much broader agreement than if we try to evaluate based on order of attachment .we hope that this method may find wider acceptance and be useful in establishing a generally applicable framework for evaluation in natural language parsing .we employ this method in an evaluation of nlpwin ( heidorn , 2000 ) , a parser developed at microsoft research without reference to the penn treebank , and , for comparison , the well-known statistical treebank parser of charniak ( 2000 ) . evaluation in natural language parsing based on treebank and non - treebank parsers
8	challenges in mapping of syntactic representations for framework-independent parser evaluation . we explore some of the issues and challenges created by the incompatibility of diverse representation schemes for syntactic parsing .in particular , we examine the problem of output format conversion for evaluation of parsers that use different formalisms .we discuss recent related efforts , and present an evaluation of different parsers that use representations that vary not only in formalisms , but also in depth of syntactic information .we attempt to compare these parsers in a domain widely used for parser evaluation , the wall street journal section of the penn treebank , and in the academic biomedical literature , where the use of parsing technologies is expected to contribute in practical applications , such as information extraction and text mining . framework - independent parser evaluation based on parsing technologies

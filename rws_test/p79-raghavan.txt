text clustering with extended user feedback . text clustering is most commonly treated as a fully automated task without user feedback .however , a variety of researchers have explored mixed-initiative clustering methods which allow a user to interact with and advise the clustering algorithm .this mixed-initiative approach is especially attractive for text clustering tasks where the user is trying to organize a corpus of documents into clusters for some particular purpose ( e.g. , clustering their email into folders that reflect various activities in which they are involved ) .this paper introduces a new approach to mixed-initiative clustering that handles several natural types of user feedback .we first introduce a new probabilistic generative model for text clustering ( the speclustering model ) and show that it outperforms the commonly used mixture of multinomials clustering model , even when used in fully autonomous mode with no user input .we then describe how to incorporate four distinct types of user feedback into the clustering algorithm , and provide experimental evidence showing substantial improvements in text clustering when this user feedback is incorporated . mixed - initiative clustering based on mixture of multinomials clustering model
the potential and actual effectiveness of interactive query expansion . in query expansion , terms from a source such as relevance feedback are added to the query . this often improves retrieval effectiveness but results are variable across queries .in interactive query expansion ( iqe ) the automatically-derived terms are instead offered as suggestions to the searcher , who decides which to add .there is little evidence of whether iqe is likely to be effective over multiple iterations in a large scale retrieval context , or whether inexperienced users can achieve this effectiveness in practice .these experiments address these two questions .a small but significant improvement in potential retrieval effectiveness is found .this is consistent across a range of topics .inexperienced users ' term selections consistently fail to improve on automatic query expansion , however .it is concluded that interactive query expansion has good potential , particularly for term sources that are poorer than relevance feedback .but it may be difficult for searchers to realise this potential without experience or training in term selection and free-text search strategies . interactive query expansion based on free - text search strategies
active learning with feedback on both features and instances . we extend the traditional active learning framework to include feedback on features in addition to labeling instances , and we execute a careful study of the effects of feature selection and human feedback on features in the setting of text categorization .our experiments on a variety of categorization tasks indicate that there is significant potential in improving classifier performance by feature re-weighting , beyond that achieved via membership queries alone ( traditional active learning ) if we have access to an oracle that can point to the important ( most predictive ) features .our experiments on human subjects indicate that human feedback on feature relevance can identify a sufficient proportion of the most relevant features ( over 50 % in our experiments ) .we find that on average , labeling a feature takes much less time than labeling a document .we devise an algorithm that interleaves labeling features and documents which significantly accelerates standard active learning in our simulation experiments .feature feedback can complement traditional active learning in applications such as news filtering , e-mail classification , and personalization , where the human teacher can have significant knowledge on the relevance of features . e - mail classification based on active learning framework
computational learning theory : survey and selected bibliography . give a rigorous , computationally detailed and plausible account of how learning can be done . learning based on computational learning theory
re-examining the potential effectiveness of interactive query expansion . much attention has been paid to the relative effectiveness of interactive query expansion versus automatic query expansion .although interactive query expansion has the potential to be an effective means of improving a search , in this paper we show that , on average , human searchers are less likely than systems to make good expansion decisions .to enable good expansion decisions , searchers must have adequate instructions on how to use interactive query expansion functionalities .we show that simple instructions on using interactive query expansion do not necessarily help searchers make good expansion decisions and discuss difficulties found in making query expansion decisions . interactive query expansion based on interactive query expansion
machine learning in automated text categorization . in the research community the dominant approach to this problem is based on machine learning techniques : a general inductive process automatically builds a classifier by learning , from a set of preclassified documents , the characteristics of the categories .the advantages of this approach over the knowledge engineering approach ( consisting in the manual definition of a classifier by domain experts ) are a very good effectiveness , considerable savings in terms of expert labor power , and straightforward portability to different domains .this survey discusses the main approaches to text categorization that fall within the machine learning paradigm .we will discuss in detail issues pertaining to three different problems , namely , document representation , classifier construction , and classifier evaluation . automated text categorization based on knowledge engineering approach
incorporating prior knowledge with weighted margin support vector machines . like many purely data-driven machine learning methods , support vector machine ( svm ) classifiers are learned exclusively from the evidence presented in the training dataset ; thus a larger training dataset is required for better performance .in some applications , there might be human knowledge available that , in principle , could compensate for the lack of data .in this paper , we propose a simple generalization of svm : weighted margin svm ( wmsvms ) that permits the incorporation of prior knowledge .we show that sequential minimal optimization can be used in training wmsvm .we discuss the issues of incorporating prior knowledge using this rather general formulation .the experimental results show that the proposed methods of incorporating prior knowledge is effective . incorporating prior knowledge based on support vector machine ( svm ) classifiers
improving generalization with active learning . active learning differs from " learning from examples " in that the learning algorithm assumes at least some control over what part of the input domain it receives information about .in some situations , active learning is provably more powerful than learning from examples alone , giving better generalization for a fixed number of training examples .in this article , we consider the problem of learning a binary concept in the absence of noise .we describe a formalism for active concept learning called selective sampling and show how it may be approximately implemented by a neural network .in selective sampling , a learner receives distribution information from the environment and queries an oracle on parts of the domain it considers " useful . "we test our implementation , called an sg- network , on three domains and observe significant improvement in generalization . active concept learning based on learning algorithm
constructing informative prior distributions from domain knowledge in text classification . supervised learning approaches to text classification are in practice often required to work with small and unsystematically collected training sets .the alternative is usually viewed as building classifiers by hand , using an expert s understanding of what features of the text are related to the class of interest .this is expensive , requires a degree of computational and linguistic sophistication , and makes it difficult to use combinations of weak predictors .we propose instead combining domain knowledge with training examples in a bayesian framework .domain knowledge is used to specify a prior distribution for parameters of a logistic regression model , and labeled training data is used to produce and find the mode of the posterior distribution .we show on three text categorization data sets that this approach can rescue what would otherwise be disastrously bad training situations , producing much more effective classifiers . constructing informative prior distributions based on supervised learning approaches

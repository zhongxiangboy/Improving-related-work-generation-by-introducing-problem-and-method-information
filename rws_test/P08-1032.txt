modeling annotated data . we consider the problem of modeling annotated datadata with multiple types where the instance of one type ( such as a caption ) serves as a description of the other type ( such as an image ) .we describe three hierarchical probabilistic mixture models which aim to describe such data , culminating in correspondence latent dirichlet allocation , a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type .we conduct experiments on the corel database of images and captions , assessing performance in terms of held-out likelihood , automatic annotation , and text-based image retrieval . correspondence latent dirichlet allocation based on hierarchical probabilistic mixture models
object recognition as machine translation : learning a lexicon for a fixed image vocabulary . we describe a model of object recognition as machine translation .in this model , recognition is a process of annotating image regions with words .firstly , images are segmented into regions , which are classified into region types using a variety of features .a mapping between region types and keywords supplied with the images , is then learned , using a method based around em .this process is analogous with learning a lexicon from an aligned bitext .for the implementation we describe , these words are nouns taken from a large vocabulary .on a large test set , the method can predict numerous words with high accuracy .simple methods identify words that cannot be predicted well .we show how to cluster words that individually are difficult to predict into clusters that can be predicted well for example , we cannot predict the distinction between train and locomotive using the current set of features , but we can predict the underlying concept .the method is trained on a substantial collection of images .extensive experimental results illustrate the strengths and weaknesses of the approach . machine translation based on em
multiple bernoulli relevance models for image and video annotation . retrieving images in response to textual queries requires some knowledge of the semantics of the picture .here , we show how we can do both automatic image annotation and retrieval ( using one word queries ) from images and videos using a multiple bernoulli relevance model .the model assumes that a training set of images or videos along with keyword annotations is provided .multiple keywords are provided for an image and the specific correspondence between a keyword and an image is not provided .each image is partitioned into a set of rectangular regions and a real-valued feature vector is computed over these regions .the relevance model is a joint probability distribution of the word annotations and the image feature vectors and is computed using the training set .the word probabilities are estimated using a multiple bernoulli model and the image feature probabilities using a non -parametric kernel density estimate .the model is then used to annotate images in a test set .we show experiments on both images from a standard corel data set and a set of video key frames from nist s video trec .comparative experiments show that the model performs better than a model based on estimating word probabilities using the popular multinomial distribution .the results also show that our model significantly outperforms previously reported results on the task of image and video annotation . automatic image annotation and retrieval based on non - parametric kernel density estimate
a model for learning the semantics of pictures . we propose an approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries .we do this using a formalism that models the generation of annotated images .we assume that every image is divided into regions , each described by a continuous-valued feature vector .given a training set of images with annotations , we compute a joint probabilistic model of image features and words which allow us to predict the probability of generating a word given the image regions .this may be used to automatically annotate and retrieve images given a word as a query .experiments show that our model significantly outperforms the best of the previously reported results on the tasks of automatic image annotation and retrieval . automatic image annotation and retrieval based on joint probabilistic model
image-to-word transformation based on dividing and vector quantizing images with words . we propose a method to make a relationship between images and words .we adopt two processes in the method , one is a process to uniformly divide each image into sub-images with key words , and the other is a process to carry out vector quantization of the sub-images .these processes lead to results which show that each sub-image can be correlated to a set of words each of which is selected from words assigned to whole images .original aspects of the method are , ( 1 ) all words assigned to a whole image are inherited to each divided sub-image , ( 2 ) the voting probability of each word for a set of divided images is estimated by the result of a vector quantization of the feature vector of sub-images .some experiments show the effectiveness of the proposed method . - word transformation based on vector quantization
content-based image retrieval at the end of the early years . the paper presents a review of 200 references in content-based image retrieval .the paper starts with discussing the working conditions of content-based retrieval : patterns of use , types of pictures , the role of semantics , and the sensory gap .subsequent sections discuss computational steps for image retrieval systems .step one of the review is image processing for retrieval sorted by color , texture , and local geometry .features for retrieval are discussed next , sorted by : accumulative and global features , salient points , object and shape features , signs , and structural combinations thereof .similarity of pictures and objects in pictures is reviewed for each of the feature types , in close connection to the types and means of feedback the user of the systems is capable of giving by interaction .we briefly discuss aspects of system engineering : databases , system architecture , and evaluation .in the concluding section , we present our view on : the driving force of the field , the heritage from computer vision , the influence on computer vision , the role of similarity and of interaction , the need for databases , the problem of evaluation , and the role of the semantic gap . content - based image retrieval based on image retrieval systems
image classification for content-based indexing . grouping images into ( semantically ) meaningful categories using low-level visual features is a challenging and important problem in content-based image retrieval .using binary bayesian classifiers , we attempt to capture high-level concepts from low-level image features under the constraint that the test image does belong to one of the classes .specifically , we consider the hierarchical classification of vacation images ; at the highest level , images are classified as indoor or outdoor ; outdoor images are further classified as city or landscape ; finally , a subset of landscape images is classified into sunset , forest , and mountain classes .we demonstrate that a small vector quantizer ( whose optimal size is selected using a modified mdl criterion ) can be used to model the class-conditional densities of the features , required by the bayesian methodology .the classifiers have been designed and evaluated on a database of 6931 vacation photographs .our system achieved a classification accuracy of 90.5 % for indoor / outdoor , 95.3 % for city / landscape , 96.6 % for sunset / forest & mountain , and 96 % for forest / mountain classification problems .we further develop a learning method to incrementally train the classifiers as additional data become available .we also show preliminary results for feature reduction using clustering techniques .our goal is to combine multiple two-class classifiers into a single hierarchical classifier . hierarchical classification of vacation images based on binary bayesian classifiers
